<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8" />
  <link rel="stylesheet" href="css/simple.css" />
  <link rel="stylesheet" href="css/style.css" />
  <title>Speech Service - Demo UI</title>

  <script>
    let audio_ctx = ''

    const start_audio = async () => {
      if (audio_ctx) {
        return
      }
      audio_ctx = new AudioContext()
      try {
        await audio_ctx.audioWorklet.addModule('js/RecorderProcessor.js')
      }
      catch (err) {
        throw new Error(`The following audioWorklet.addModule error occurred: ${err}`)
      }
      try {
        stream = await navigator.mediaDevices.getUserMedia({ audio: true })
      } catch (err) {
        throw new Error(`The following mediaDevices.getUserMedia error occurred: ${err}`)
      }
      const audioTracks = stream.getAudioTracks()
      if (audioTracks.length !== 1) {
        throw new Error('Too many tracks!')
      }
      const audioTrack = audioTracks[0]

      const recorder = audio_ctx.createMediaStreamSource(stream)

      // const gain = audio_ctx.createGain()
      // gain.gain.setValueAtTime(2, audio_ctx.currentTime)

      // const compressor = audio_ctx.createDynamicsCompressor()
      // compressor.threshold.setValueAtTime(-50, audio_ctx.currentTime)
      // compressor.knee.setValueAtTime(40, audio_ctx.currentTime)
      // compressor.ratio.setValueAtTime(20, audio_ctx.currentTime)
      // compressor.attack.setValueAtTime(0, audio_ctx.currentTime)
      // compressor.release.setValueAtTime(0.25, audio_ctx.currentTime)

      const recorder_worklet = new AudioWorkletNode(audio_ctx, 'recorder.worklet')

      const ws = new WebSocket(`${(window.location.protocol === "https:") ? "wss://" : "ws://"}${window.location.host}/transcribe_record/ws`)
      ws.onmessage = ev => {
        obj = JSON.parse(ev.data)
        src_lang.value = obj.language
        obj.segments.forEach(s => tgt_text.textContent += s.text + '\n')
      }
      ws.onerror = ev => tgt_text.textContent = 'WebSocket error: ' + ev

      recorder.connect(recorder_worklet)
      // recorder.connect(compressor)
      // compressor.connect(recorder_worklet)
      recorder_worklet.connect(audio_ctx.destination)

      const buffer_size = 16000 * 30
      const buffer = new Float32Array(buffer_size)
      let samples_written = 0

      recorder_worklet.port.onmessage = ev => {
        if (typeof (ev.data) === 'number') {
          const db = ev.data // decibel
          const min = -30
          const max = 50
          const volume_pos = (Math.max(min, db) - min) / (max - min) * 100
          // volume animation
          record_btn.style.backgroundPosition = -volume_pos + '%'

          if (ev.data <= -10) {
            if (samples_written > 16000) {
              console.log(`Send after sentence end: ${samples_written}`)
              ws.send(buffer.slice(0, samples_written))
            }
            samples_written = 0
          }
          return
        }
        msg_buffer = ev.data
        console.log(`Receiving audio data: ${msg_buffer.length} (${samples_written})`)
        for (let i = 0; i < msg_buffer.length; i++) {
          buffer[samples_written++] = msg_buffer[i]
          if (samples_written === buffer_size) {
            console.log(`Send because buffer full: ${samples_written}`)
            ws.send(buffer.slice(0, samples_written))
            samples_written = 0
          }
        }
      }
    }

    window.onload = _ => {
      const record_btn = document.getElementById('record_btn')
      const src_lang = document.getElementById('src_lang')
      const tgt_text = document.getElementById('tgt_text')

      // init record action events
      record_btn.onclick = async _ => {
        if (!audio_ctx) {
          await start_audio()
          audio_ctx.resume().then(() => record_btn.textContent = "Recording... (Click stop for suspending record)")
          // init volume animation
          record_btn.style.background = 'linear-gradient(to left, rgb(255, 0, 34) 50%, #0d47a1 50%)'
          record_btn.style.backgroundSize = '200% 100%'
        } else if (audio_ctx.state === "running") {
          audio_ctx.suspend().then(() => record_btn.textContent = "Resume recording")
        } else if (audio_ctx.state === "suspended") {
          audio_ctx.resume().then(() => {
            record_btn.textContent = "Recording... (Click stop for suspending record)"
          })
        }
      }
      // init language dropdowns
      fetch('/languages', {
        headers: {
          'Accept': 'application/json'
        }
      })
        .then(async res => {
          if (res.status === 200) {
            return res.json()
          }
          throw new Error(await res.text())
        })
        .then(json => {
          for (let i = 0; i < json.length; i++) {
            const obj = json[i]
            const el = document.createElement('option')
            el.value = obj.language_id
            el.textContent = obj.language_name
            src_lang.appendChild(el)
          }
        })
        .catch(err => tgt_text.textContent = err)
    }
  </script>
</head>

<body>
  <h1>Transcribe Recorder</h1>
  <p>In this demo you can speak into the micro and receive a transcription in real time. The recording snippets are sent
    to the server via websocket-based services, processed there and the response is sent back via websockets. The files
    are deleted immediately after processing.<br>
    This experiment isn't very stable yet, because of latency issues and wrong block sizes etc. Better use the record
    function in
    <a href="transcribe_upload.html">Transcribe Upload</a>.
  </p>
  <button id="record_btn">Start recording</button>
  <label for="src_lang">Source language:</label>
  <select id="src_lang" disabled>
    <option value="">Will be autodetected...</option>
  </select>
  <label for="tgt_text">Transcription:</label>
  <pre id="tgt_text"></pre>
</body>

</html>