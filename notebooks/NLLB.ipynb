{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrePankraz/speech_service/blob/main/notebooks/NLLB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aiz5wUyrg78V"
      },
      "source": [
        "## Translation - No Language Left Behind (NLLB)\n",
        "The following Notebook can translate text between 200 languages. It's based on the Meta model [NLLB](https://ai.facebook.com/research/no-language-left-behind/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAPChOdCghjA"
      },
      "source": [
        "# Set-up environment\n",
        "We need following packages:\n",
        "\n",
        "*   optional: bitsandbytes & accelerate for [8bit model inference](https://huggingface.co/blog/hf-bitsandbytes-integration)\n",
        "*   [transformers](https://github.com/huggingface/transformers) for NLLB model\n",
        "*   [sentence_cleaner_splitter](https://github.com/facebookresearch/LASER/tree/main/utils) from project [LASER](https://github.com/facebookresearch/LASER) for sentence splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgE5lQP7gYnC",
        "outputId": "303180c5-d109-4a89-9194-6f08f0cf79cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install --quiet accelerate\n",
        "!pip install --quiet bitsandbytes\n",
        "!pip install --quiet git+https://github.com/huggingface/transformers.git # Install latest version of transformers\n",
        "!pip install --quiet sentence_cleaner_splitter@git+https://github.com/facebookresearch/LASER.git#subdirectory=utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YB6DMVBExDFN"
      },
      "source": [
        "# Check GPU\n",
        "The following experiments can be run without a GPU, but it will take much longer!\n",
        "\n",
        "See Colab Menu: Runtime / Change type.\n",
        "\n",
        "Check if GPU available:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfrJ_WjWxCUj",
        "outputId": "fc03a967-4800-44b4-e096-98f2f03d0cad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Nov  3 15:22:23 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   68C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kB9JOBuQnULY"
      },
      "source": [
        "# Set-up AI-model for translation\n",
        "We need a pre-trained tokenizer and a model, that are downloaded from [Hugging Faces](https://huggingface.co/models?sort=downloads&search=facebook%2Fnllb). \n",
        "\n",
        "Multiple model sizes are available, to adapt to the GPU VRAM constraints. Only the big models provide enough quality, the smaller are just for quick tests.\n",
        "\n",
        "With the param \"load_in_8bit=True\" you can also load bigger models, but they are slow at inference time. See [bitsandbytes](https://huggingface.co/blog/hf-bitsandbytes-integration).\n",
        "(This doesn't always work: 'ERROR: Your GPU does not support Int8 Matmul!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cu04_XOCf0-c",
        "outputId": "71309a73-9829-4863-fd14-5ddd58dceac7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, pipeline\n",
        "\n",
        "# Load model NLLB\n",
        "# facebook/nllb-200-distilled-600M, facebook/nllb-200-distilled-1.3B, facebook/nllb-200-3.3B\n",
        "# VRAM at least: 4 | 8 | 16 GB VRAM\n",
        "model_id = 'facebook/nllb-200-distilled-1.3B'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_id, device_map='auto', load_in_8bit=False)\n",
        "\n",
        "model.device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIG7UBFLoQnq"
      },
      "source": [
        "A source and a target language are to be provided to the translation pipeline. The supported language IDs are visible with this map from project [LASER](https://github.com/facebookresearch/LASER), which has been used for NLLB training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSeWH1HakH8i",
        "outputId": "74fb420a-45cf-47df-dfe1-2c367ef13e75"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "| 2022-11-03 15:23:48,099 | \u001b[1;32mINFO\u001b[0m | khmer-nltk | Loaded model from /usr/local/lib/python3.7/dist-packages/khmernltk/word_tokenize/sklearn_crf_ner_10000.sav |\n",
            "INFO:khmer-nltk:Loaded model from /usr/local/lib/python3.7/dist-packages/khmernltk/word_tokenize/sklearn_crf_ner_10000.sav\n",
            "| 2022-11-03 15:23:48,130 | \u001b[1;32mINFO\u001b[0m | khmer-nltk | Loaded model from /usr/local/lib/python3.7/dist-packages/khmernltk/pos_tag/sklearn_crf_pos_alt_0.9846.sav |\n",
            "INFO:khmer-nltk:Loaded model from /usr/local/lib/python3.7/dist-packages/khmernltk/pos_tag/sklearn_crf_pos_alt_0.9846.sav\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'ace_Arab': 'ace_Arab',\n",
              " 'ace_Latn': 'ace_Latn',\n",
              " 'acm_Arab': 'acm',\n",
              " 'acq_Arab': 'acq',\n",
              " 'aeb_Arab': 'aeb',\n",
              " 'afr_Latn': 'afr',\n",
              " 'ajp_Arab': 'ajp',\n",
              " 'aka_Latn': 'aka',\n",
              " 'amh_Ethi': 'amh',\n",
              " 'apc_Arab': 'apc',\n",
              " 'arb_Arab': 'ara_Arab',\n",
              " 'arb_Latn': 'ara_Latn',\n",
              " 'ars_Arab': 'ars',\n",
              " 'ary_Arab': 'ary',\n",
              " 'arz_Arab': 'arz',\n",
              " 'asm_Beng': 'asm',\n",
              " 'ast_Latn': 'ast',\n",
              " 'awa_Deva': 'awa',\n",
              " 'ayr_Latn': 'ayr',\n",
              " 'azb_Arab': 'azb',\n",
              " 'azj_Latn': 'azj',\n",
              " 'bak_Cyrl': 'bak',\n",
              " 'bam_Latn': 'bam',\n",
              " 'ban_Latn': 'ban',\n",
              " 'bel_Cyrl': 'bel',\n",
              " 'bem_Latn': 'bem',\n",
              " 'ben_Beng': 'ben',\n",
              " 'bho_Deva': 'bho',\n",
              " 'bjn_Arab': 'bjn_Arab',\n",
              " 'bjn_Latn': 'bjn_Latn',\n",
              " 'bod_Tibt': 'bod',\n",
              " 'bos_Latn': 'bos',\n",
              " 'bug_Latn': 'bug',\n",
              " 'bul_Cyrl': 'bul',\n",
              " 'cat_Latn': 'cat',\n",
              " 'ceb_Latn': 'ceb',\n",
              " 'ces_Latn': 'ces',\n",
              " 'cjk_Latn': 'cjk',\n",
              " 'ckb_Arab': 'ckb',\n",
              " 'crh_Latn': 'crh_Latn',\n",
              " 'cym_Latn': 'cym',\n",
              " 'dan_Latn': 'dan',\n",
              " 'deu_Latn': 'deu',\n",
              " 'dik_Latn': 'dik',\n",
              " 'diq_Latn': 'diq',\n",
              " 'dyu_Latn': 'dyu',\n",
              " 'dzo_Tibt': 'dzo',\n",
              " 'ell_Grek': 'ell',\n",
              " 'eng_Latn': 'eng',\n",
              " 'epo_Latn': 'epo',\n",
              " 'est_Latn': 'est',\n",
              " 'eus_Latn': 'eus',\n",
              " 'ewe_Latn': 'ewe',\n",
              " 'fao_Latn': 'fao',\n",
              " 'pes_Arab': 'fas',\n",
              " 'fij_Latn': 'fij',\n",
              " 'fin_Latn': 'fin',\n",
              " 'fon_Latn': 'fon',\n",
              " 'fra_Latn': 'fra',\n",
              " 'fur_Latn': 'fur',\n",
              " 'fuv_Latn': 'fuv',\n",
              " 'gla_Latn': 'gla',\n",
              " 'gle_Latn': 'gle',\n",
              " 'glg_Latn': 'glg',\n",
              " 'grn_Latn': 'grn',\n",
              " 'guj_Gujr': 'guj',\n",
              " 'hat_Latn': 'hat',\n",
              " 'hau_Latn': 'hau',\n",
              " 'heb_Hebr': 'heb',\n",
              " 'hin_Deva': 'hin',\n",
              " 'hne_Deva': 'hne',\n",
              " 'hrv_Latn': 'hrv',\n",
              " 'hun_Latn': 'hun',\n",
              " 'hye_Armn': 'hye',\n",
              " 'ibo_Latn': 'ibo',\n",
              " 'ilo_Latn': 'ilo',\n",
              " 'ind_Latn': 'ind',\n",
              " 'isl_Latn': 'isl',\n",
              " 'ita_Latn': 'ita',\n",
              " 'jav_Latn': 'jav',\n",
              " 'jpn_Jpan': 'jpn',\n",
              " 'kab_Latn': 'kab',\n",
              " 'kac_Latn': 'kac',\n",
              " 'kam_Latn': 'kam',\n",
              " 'kan_Knda': 'kan',\n",
              " 'kas_Arab': 'kas_Arab',\n",
              " 'kas_Deva': 'kas_Deva',\n",
              " 'kat_Geor': 'kat',\n",
              " 'knc_Arab': 'kau_Arab',\n",
              " 'knc_Latn': 'kau_Latn',\n",
              " 'kaz_Cyrl': 'kaz',\n",
              " 'kbp_Latn': 'kbp',\n",
              " 'kea_Latn': 'kea',\n",
              " 'khm_Khmr': 'khm',\n",
              " 'kik_Latn': 'kik',\n",
              " 'kin_Latn': 'kin',\n",
              " 'kir_Cyrl': 'kir',\n",
              " 'kmb_Latn': 'kmb',\n",
              " 'kon_Latn': 'kon',\n",
              " 'kor_Hang': 'kor',\n",
              " 'kmr_Latn': 'kur',\n",
              " 'lao_Laoo': 'lao',\n",
              " 'lvs_Latn': 'lav',\n",
              " 'lij_Latn': 'lij',\n",
              " 'lim_Latn': 'lim',\n",
              " 'lin_Latn': 'lin',\n",
              " 'lit_Latn': 'lit',\n",
              " 'lmo_Latn': 'lmo',\n",
              " 'ltg_Latn': 'ltg',\n",
              " 'ltz_Latn': 'ltz',\n",
              " 'lua_Latn': 'lua',\n",
              " 'lug_Latn': 'lug',\n",
              " 'luo_Latn': 'luo',\n",
              " 'lus_Latn': 'lus',\n",
              " 'mag_Deva': 'mag',\n",
              " 'mai_Deva': 'mai',\n",
              " 'mal_Mlym': 'mal',\n",
              " 'mar_Deva': 'mar',\n",
              " 'min_Arab': 'min_Arab',\n",
              " 'min_Latn': 'min_Latn',\n",
              " 'mkd_Cyrl': 'mkd',\n",
              " 'plt_Latn': 'mlg',\n",
              " 'mlt_Latn': 'mlt',\n",
              " 'khk_Cyrl': 'mon',\n",
              " 'mos_Latn': 'mos',\n",
              " 'mri_Latn': 'mri',\n",
              " 'zsm_Latn': 'msa',\n",
              " 'mya_Mymr': 'mya',\n",
              " 'nld_Latn': 'nld',\n",
              " 'nno_Latn': 'nno',\n",
              " 'nob_Latn': 'nob',\n",
              " 'npi_Deva': 'npi',\n",
              " 'nso_Latn': 'nso',\n",
              " 'nus_Latn': 'nus',\n",
              " 'nya_Latn': 'nya',\n",
              " 'oci_Latn': 'oci',\n",
              " 'gaz_Latn': 'orm',\n",
              " 'ory_Orya': 'ory',\n",
              " 'pag_Latn': 'pag',\n",
              " 'pan_Guru': 'pan',\n",
              " 'pap_Latn': 'pap',\n",
              " 'pol_Latn': 'pol',\n",
              " 'por_Latn': 'por',\n",
              " 'prs_Arab': 'prs',\n",
              " 'pbt_Arab': 'pus',\n",
              " 'quy_Latn': 'que',\n",
              " 'ron_Latn': 'ron',\n",
              " 'run_Latn': 'run',\n",
              " 'rus_Cyrl': 'rus',\n",
              " 'sag_Latn': 'sag',\n",
              " 'san_Deva': 'san',\n",
              " 'sat_Olck': 'sat',\n",
              " 'scn_Latn': 'scn',\n",
              " 'shn_Mymr': 'shn',\n",
              " 'sin_Sinh': 'sin',\n",
              " 'slk_Latn': 'slk',\n",
              " 'slv_Latn': 'slv',\n",
              " 'smo_Latn': 'smo',\n",
              " 'sna_Latn': 'sna',\n",
              " 'snd_Arab': 'snd',\n",
              " 'som_Latn': 'som',\n",
              " 'sot_Latn': 'sot',\n",
              " 'spa_Latn': 'spa',\n",
              " 'als_Latn': 'sqi',\n",
              " 'srd_Latn': 'srd',\n",
              " 'srp_Cyrl': 'srp_Cyrl',\n",
              " 'ssw_Latn': 'ssw',\n",
              " 'sun_Latn': 'sun',\n",
              " 'swe_Latn': 'swe',\n",
              " 'swh_Latn': 'swh',\n",
              " 'szl_Latn': 'szl',\n",
              " 'tam_Taml': 'tam',\n",
              " 'tat_Cyrl': 'tat_Cyrl',\n",
              " 'tel_Telu': 'tel',\n",
              " 'tgk_Cyrl': 'tgk',\n",
              " 'tgl_Latn': 'tgl',\n",
              " 'tha_Thai': 'tha',\n",
              " 'tir_Ethi': 'tir',\n",
              " 'taq_Latn': 'tmh_Latn',\n",
              " 'taq_Tfng': 'tmh_Tfng',\n",
              " 'ton_Latn': 'ton',\n",
              " 'tpi_Latn': 'tpi',\n",
              " 'tsn_Latn': 'tsn',\n",
              " 'tso_Latn': 'tso',\n",
              " 'tuk_Latn': 'tuk',\n",
              " 'tum_Latn': 'tum',\n",
              " 'tur_Latn': 'tur',\n",
              " 'twi_Latn': 'twi',\n",
              " 'tzm_Tfng': 'tzm',\n",
              " 'uig_Arab': 'uig',\n",
              " 'ukr_Cyrl': 'ukr',\n",
              " 'umb_Latn': 'umb',\n",
              " 'urd_Arab': 'urd',\n",
              " 'uzn_Latn': 'uzb',\n",
              " 'vec_Latn': 'vec',\n",
              " 'vie_Latn': 'vie',\n",
              " 'war_Latn': 'war',\n",
              " 'wol_Latn': 'wol',\n",
              " 'xho_Latn': 'xho',\n",
              " 'ydd_Hebr': 'yid',\n",
              " 'yor_Latn': 'yor',\n",
              " 'yue_Hant': 'yue',\n",
              " 'zho_Hans': 'zho_Hans',\n",
              " 'zho_Hant': 'zho_Hant',\n",
              " 'zul_Latn': 'zul'}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Optional output...\n",
        "from sentence_cleaner_splitter.sentence_split import split_lang_code_map\n",
        "\n",
        "split_lang_code_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ranNVALqs0gj"
      },
      "outputs": [],
      "source": [
        "src_lang='deu_Latn'\n",
        "tgt_lang='rus_Cyrl'\n",
        "\n",
        "src_text = '''\n",
        "Menschheitstraum\n",
        "Das Verstehen einer Sprache, ohne sie gelernt zu haben, ist ein alter Menschheitstraum (Turmbau zu Babel, J. Bechers numerische Interlingua, Timerio, Babelfisch, Pfingstwunder, Science-Fiction-Geschichten). Die Erfindung der Computer in Kombination mit der Beschäftigung mit dem Phänomen Sprache als wissenschaftliche Disziplin (Sprachwissenschaft) hat zum ersten Mal einen konkreten Weg zur Erfüllung dieses Traums geöffnet.\n",
        "\n",
        "Geschichte\n",
        "Bis zum heutigen Tag hat das militärische Interesse den Weg der MÜ entscheidend geprägt. Eines der frühesten Projekte war ein Russisch-Englisch-Übersetzungsprogramm für das US-Militär. Trotz seiner anekdotenhaft schlechten Qualität genoss das Programm hohe Popularität unter US-Militärs, die sich zum ersten Mal ohne den Umweg über Dritte (Dolmetscher und Übersetzer) selbst zumindest einen Eindruck vom Inhalt russischer Dokumente verschaffen konnten.\n",
        "\n",
        "Der 1966 für das Verteidigungsministerium der Vereinigten Staaten erstellte ALPAC-Bericht[1] bescheinigte der MÜ grundsätzliche Unrealisierbarkeit und brachte mit einem Schlag die Forschung für fast 20 Jahre praktisch ganz zum Erliegen. Erst in den 1980er Jahren begannen Elektrokonzerne wie die Siemens AG (Metal-Projekt) erneut mit der Forschung. Zu diesen Vorhaben zählt auch die Forschungsarbeit im Sonderforschungsbereich „Elektronische Sprachforschung“ an der Universität des Saarlandes. Hier wurde das System „SUSY“ entwickelt, das in der Lage war, aus dem Deutschen und ins Deutsche zu übersetzen.[2] Ein weiteres System des Sonderforschungsbereichs war ASCOF, in dem neben morpho-syntaktischen auch semantische Informationen für die Übersetzung herangezogen wurden.[3] In der gleichen Zeit initiierte die japanische Regierung das Fünfte-Generation-Projekt, bei dem MÜ vom Englischen ins Japanische zunächst auf der Basis der Programmiersprache Prolog implementiert wurde. Die enge Zusammenarbeit zwischen Universitäten, Elektrokonzernen und Regierung führte zu den weltweit ersten kommerziellen MÜ-Programmen für PCs und hat Japan in die Führungsposition der MÜ-Forschung weltweit gebracht. In den 1990er Jahren lief in Deutschland das BMBF-Leitprojekt Verbmobil, dessen Ziel es war, deutsche, englische und japanische gesprochene Dialogsprache zu dolmetschen. Das Verbmobil-System sollte gesprochene Spontansprache erkennen, die Eingabe analysieren, übersetzen, einen Satz erzeugen und ihn aussprechen.[4]\n",
        "\n",
        "In den 2000er Jahren kamen vermehrt statistische Verfahren zum Einsatz. So bietet Google seit 2006 ein statistisches Übersetzungssystem an.[5] Auch regelbasierte Ansätze wurden weiterentwickelt. Eines der bekanntesten Forschungsprojekte dieser Art ist die freie Software Apertium, die von der spanischen Regierung und der Regierung von Katalonien finanziert und an der Universität Alicante weiterentwickelt wird.\n",
        "\n",
        "Der Stand der MÜ im Jahr 2010 wurde von vielen Menschen als unbefriedigend bewertet. Grundsätzlich versteht die Wissenschaft menschliche Sprache aber noch unzureichend. Die meisten Sprachwissenschaftler gingen gar davon aus, dass maschineller Übersetzung ohne über das reine Sprachverständnis weit hinausgehende Kompetenzen automatischer Systeme grundsätzliche Grenzen gesetzt sind, da viele Übersetzungen zudem große Mengen an konzeptuellem Wissen, Metawissen sowie Kenntnisse über die Konstitution menschlicher Umwelt allgemein und über die Konventionen sozialer Interaktion erfordern.\n",
        "\n",
        "Seit dem Jahr 2016 werden für Übersetzungsprogramme zunehmend künstliche neuronale Netze, d. h. künstliche Intelligenzen eingesetzt, wodurch der Fortschritt rasant zunahm. Beispiele sind DeepL, Google Übersetzer, Yandex.Translate sowie der Bing Translator, die fortan deutlich bessere Ergebnisse erzielten.[6]\n",
        "\n",
        "Im März 2018 teilte Microsoft mit, durch eine KI Chinesisch-Englisch-Übersetzungen mit der Qualität eines professionellen menschlichen Übersetzers zu erreichen. Das sei ein Durchbruch bei der maschinellen Übersetzung, den Microsoft nicht so früh erwartet habe.[7][8]\n",
        "\n",
        "Der Bedarf an MÜ-Anwendungen steigt weiter:\n",
        "\n",
        "Viele Texte sind heute digital verfügbar (also leicht für den Computer zu verarbeiten).\n",
        "Die Globalisierung erfordert die Übertragung von immer mehr Texten in immer mehr Sprachen (der Markt für Übersetzung verdoppelt sich alle vier Jahre), während die Popularität des Berufs des Übersetzers/Dolmetschers stagniert.\n",
        "Gerade von nur wenigen Westeuropäern/Amerikanern gesprochene beziehungsweise für diese schwierig zu erlernende Sprachen aus Regionen, deren Bewohner ihrerseits kaum westliche Sprachen sprechen, werden immer wichtiger:\n",
        "kommerziell wichtig: die ostasiatischen Sprachen Chinesisch, Koreanisch und Japanisch; sowie Thai.\n",
        "militärisch wichtig: Sprachen der internationalen Konfliktregionen, vor allem mit Beteiligung des US-Militärs. 2003 haben gleich mehrere US-Software-Unternehmen Übersetzungsprogramme für Arabisch und Paschtu (eine der Sprachen in Afghanistan und Grenzregionen Pakistans) herausgebracht. Ebenfalls 2003 hat die DARPA einen Blind-Wettbewerb für eine unbekannte Ausgangssprache durchgeführt. 2011 wurde das BOLT-Programm gestartet, das zum Ziel hat, die Erforschung der Übersetzung chinesischer und arabischer Texte ins Englische zu fördern.[9][10]\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czIDeF0no0yB"
      },
      "source": [
        "# Set-up translation pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sZ3IvcEnf1zx"
      },
      "outputs": [],
      "source": [
        "translation_pipeline = pipeline('translation',\n",
        "                                model=model,\n",
        "                                tokenizer=tokenizer,\n",
        "                                src_lang=src_lang,\n",
        "                                tgt_lang=tgt_lang,\n",
        "                                max_length=512,\n",
        "                                device=model.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCZ7Yb4SptVg"
      },
      "source": [
        "# Translate\n",
        "Very long sequences could run into the following problems:\n",
        "*    'Token indices sequence length is longer than the specified maximum sequence length for this model (1320 > 1024).'\n",
        "*    'Your input_length: 1320 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)'\n",
        "\n",
        "The model is trained on sentence level and problems are possible with longer sequences. So it's a good idea to split the text.\n",
        "\n",
        "See paper: 'The maximum sequence length during training is 512 for both the encoder and the decoder.'\n",
        "\n",
        "The model is restricted to 512 tokens, which means less than 500 words! Text documents should be split into sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlOGWyS0po0n",
        "outputId": "90032f08-a102-4ce7-c4d3-da346055b919"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1320 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Your input_length: 1320 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'translation_text': 'Впервые в истории понимание языка без его изучения стало для человечества мечтой, которая продолжает развиваться и сегодня военный интерес к современным технологиям решающим образом способствует достижению высокого качества, одна из самых успешных разработок, которая была предпринята Microsoft с марта 2006 года, - это программа перевода на русский язык для американской армии. Несмотря на то, что результаты ее разработки в Восточно-американском университете Google стали известны на протяжении более чем четырех лет, программа перевода на английский язык стала настолько популярной на мировом рынке, что в течение почти 20 лет она стала одним из самых популярных в мире программ перевода на английский язык, что стало все более важным для японского языка. В частности, в 1980 году была разработана программа перевода на английский язык (например, в США, Японии, Японии, Японии, Японии, Японии, Китае, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии, Японии,'}]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "translation_pipeline(src_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmiA27zwvIpJ"
      },
      "source": [
        "# Set-up Sentence Splitter\n",
        "Use sentence splitter form project [LASER](https://github.com/facebookresearch/LASER), which has been used for NLLB training. This is a small AI-model, which will be downloaded in the background."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "h0Vr6f9psxXy"
      },
      "outputs": [],
      "source": [
        "from sentence_cleaner_splitter.cleaner_splitter import SentenceSplitClean\n",
        "\n",
        "sentence_splitter = SentenceSplitClean(src_lang, 'default')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJw5ZBaTvfFV"
      },
      "source": [
        "# Split text into sentences\n",
        "Replace or remove some special chars like zero-width spaces or non-breaking spaces. The NLLB model doesn't understand them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "oHMFT2jDtc5e"
      },
      "outputs": [],
      "source": [
        "norm_texts = []\n",
        "for _, _, line in sentence_splitter(src_text.replace('\\u200b', ' ')):\n",
        "    norm_texts.append(line.strip())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BOHYWbEwNLY"
      },
      "source": [
        "# Translate text\n",
        "The NLLB model doesn't always map empty lines to empty lines in other languages! This seems to be a bug in the model? We have to postprocess this or insert a different input token for empty lines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTKjrZ82tqUN",
        "outputId": "53efadfe-abf1-4e6b-af48-c91abd47573d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'translation_text': 'Мечта человечества'},\n",
              " {'translation_text': 'Понимание языка без его изучения - это древняя мечта человечества (Бавлинская башня, цифровой интерлингва Дж. Бекера, Тимерий, Вавилонская рыбка, чудеса пингвина, научные истории).'},\n",
              " {'translation_text': 'Изобретение компьютеров в сочетании с изучением феномена языка как научной дисциплины (лингвистика) открыло конкретный путь к осуществлению этой мечты.'},\n",
              " {'translation_text': 'Продолжение'},\n",
              " {'translation_text': 'История'},\n",
              " {'translation_text': 'До сегодняшнего дня военные интересы определяют путь МУ.'},\n",
              " {'translation_text': 'Одним из первых проектов была программа перевода русского на английский для американских военных.'},\n",
              " {'translation_text': 'Несмотря на его анекдотно плохое качество, программа пользовалась большой популярностью среди военных США, которые впервые смогли получить хотя бы представление о содержании российских документов без обхода через третьих лиц (переводчиков и переводчиков).'},\n",
              " {'translation_text': 'Продолжение'},\n",
              " {'translation_text': 'В 1966 году для Министерства обороны США был подготовлен доклад ALPAC[1] , который подтвердил, что МУ в принципе не осуществимо и в один момент практически полностью остановил исследования на протяжении почти 20 лет.'},\n",
              " {'translation_text': 'Только в 1980-х годах электроконцерны, такие как Siemens AG (проект металлов), вновь начали исследования.'},\n",
              " {'translation_text': 'Среди этих проектов - исследовательская работа в специальном исследовательском центре \"Электронные языковые исследования\" в Саарском университете.'},\n",
              " {'translation_text': 'Здесь была разработана система \"SUSY\", которая была способна переводить с немецкого на немецкий язык.[2] Еще одной системой специального исследовательского направления была ASCOF, в которой помимо морфосинтаксической также семантическая информация была использована для перевода.[3] В то же время японское правительство инициировало проект пятого поколения, в котором МУ с английского на японский язык сначала был реализован на основе языка программирования Prolog.'},\n",
              " {'translation_text': 'Тесное сотрудничество между университетами, электротехническими компаниями и правительством привело к первым в мире коммерческим программам по исследованию ПК и сделало Японию лидером в области ПК в мире.'},\n",
              " {'translation_text': 'В 1990-х годах в Германии работал ведущий проект BMBF Verbmobil, целью которого было перевод немецкого, английского и японского языков разговорного диалога.'},\n",
              " {'translation_text': 'Система Verbmobil должна была распознавать разговорный спонтанный язык, анализировать ввод, переводить, создавать предложение и произносить его.[4]'},\n",
              " {'translation_text': 'Продолжение'},\n",
              " {'translation_text': 'В 2000-х годах стали использоваться все больше статистических методов.'},\n",
              " {'translation_text': 'Так, с 2006 года Google предлагает статистическую систему перевода.[5] Также были разработаны подходы, основанные на правилах.'},\n",
              " {'translation_text': 'Одним из самых известных исследовательских проектов такого рода является свободное программное обеспечение Apertium, финансируемое правительством Испании и правительством Каталонии и разрабатываемое в Университете Аликанте.'},\n",
              " {'translation_text': 'Продолжение'},\n",
              " {'translation_text': 'Состояние МР в 2010 году было оценено многими людьми как неудовлетворительное.'},\n",
              " {'translation_text': 'Но в принципе наука еще недостаточно понимает человеческий язык.'},\n",
              " {'translation_text': 'Большинство лингвистов даже полагали, что машинный перевод без компетенций автоматических систем, выходящих далеко за рамки чистого понимания языка, имеет фундаментальные ограничения, поскольку многие переводы также требуют больших объемов концептуальных знаний, метазнаний, а также знаний о конституции человеческой среды в целом и о конвенциях социального взаимодействия.'},\n",
              " {'translation_text': 'Продолжение'},\n",
              " {'translation_text': 'С 2016 года в переводе программ все чаще используются искусственные нейронные сети, т.е. искусственный интеллект, что привело к быстрому росту прогресса.'},\n",
              " {'translation_text': 'Примеры: DeepL, Google Translator, Yandex.Translate, а также Bing Translator, которые с тех пор добились значительно лучших результатов.[6]'},\n",
              " {'translation_text': 'Продолжение'},\n",
              " {'translation_text': 'В марте 2018 года Microsoft объявила, что через ИИ она достигнет качества профессионального человеческого переводчика в переводе с китайского на английский.'},\n",
              " {'translation_text': 'Это прорыв в машинном переводе, которого Microsoft не ожидала так рано.[7][8]'},\n",
              " {'translation_text': 'Продолжение'},\n",
              " {'translation_text': 'Потребность в МУ продолжает расти:'},\n",
              " {'translation_text': 'Продолжение'},\n",
              " {'translation_text': 'Многие тексты сегодня доступны в цифровом виде (то есть легко обрабатываются компьютером).'},\n",
              " {'translation_text': 'Глобализация требует перевода все большего количества текстов на все больше языков (рынок переводов удваивается каждые четыре года), в то время как популярность профессии переводчика/переводчика стагнирует.'},\n",
              " {'translation_text': 'Особенно важными становятся языки, на которых говорят немногие западные европейцы/американцы, или языки, которые трудно изучать из регионов, жители которых в свою очередь мало говорят на западных языках:'},\n",
              " {'translation_text': 'коммерчески важные: восточноазиатские языки китайский, корейский и японский; а также тайский.'},\n",
              " {'translation_text': 'военно-значимые: языки регионов международных конфликтов, в частности, с участием американских военных.'},\n",
              " {'translation_text': 'В 2003 году несколько американских программных компаний выпустили программы для перевода на арабский и пашту (один из языков Афганистана и приграничных районов Пакистана).'},\n",
              " {'translation_text': 'Также в 2003 году DARPA провела конкурс для слепых на неизвестный исходный язык.'},\n",
              " {'translation_text': 'В 2011 году была запущена программа BOLT, целью которой является содействие исследованию перевода китайских и арабских текстов на английский язык.'}]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tgt_texts = translation_pipeline(norm_texts)\n",
        "\n",
        "tgt_texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "empVi_QSwRU9"
      },
      "source": [
        "# Show sentences and their matching translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiSzYqpsuS7Q",
        "outputId": "0f7f95fb-0806-4f0b-c401-2fc6af441c60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'Menschheitstraum' ---> 'Мечта человечества'\n",
            "'Das Verstehen einer Sprache, ohne sie gelernt zu haben, ist ein alter Menschheitstraum (Turmbau zu Babel, J. Bechers numerische Interlingua, Timerio, Babelfisch, Pfingstwunder, Science-Fiction-Geschichten).' ---> 'Понимание языка без его изучения - это древняя мечта человечества (Бавлинская башня, цифровой интерлингва Дж. Бекера, Тимерий, Вавилонская рыбка, чудеса пингвина, научные истории).'\n",
            "'Die Erfindung der Computer in Kombination mit der Beschäftigung mit dem Phänomen Sprache als wissenschaftliche Disziplin (Sprachwissenschaft) hat zum ersten Mal einen konkreten Weg zur Erfüllung dieses Traums geöffnet.' ---> 'Изобретение компьютеров в сочетании с изучением феномена языка как научной дисциплины (лингвистика) открыло конкретный путь к осуществлению этой мечты.'\n",
            "'Geschichte' ---> 'История'\n",
            "'Bis zum heutigen Tag hat das militärische Interesse den Weg der MÜ entscheidend geprägt.' ---> 'До сегодняшнего дня военные интересы определяют путь МУ.'\n",
            "'Eines der frühesten Projekte war ein Russisch-Englisch-Übersetzungsprogramm für das US-Militär.' ---> 'Одним из первых проектов была программа перевода русского на английский для американских военных.'\n",
            "'Trotz seiner anekdotenhaft schlechten Qualität genoss das Programm hohe Popularität unter US-Militärs, die sich zum ersten Mal ohne den Umweg über Dritte (Dolmetscher und Übersetzer) selbst zumindest einen Eindruck vom Inhalt russischer Dokumente verschaffen konnten.' ---> 'Несмотря на его анекдотно плохое качество, программа пользовалась большой популярностью среди военных США, которые впервые смогли получить хотя бы представление о содержании российских документов без обхода через третьих лиц (переводчиков и переводчиков).'\n",
            "'Der 1966 für das Verteidigungsministerium der Vereinigten Staaten erstellte ALPAC-Bericht[1] bescheinigte der MÜ grundsätzliche Unrealisierbarkeit und brachte mit einem Schlag die Forschung für fast 20 Jahre praktisch ganz zum Erliegen.' ---> 'В 1966 году для Министерства обороны США был подготовлен доклад ALPAC[1] , который подтвердил, что МУ в принципе не осуществимо и в один момент практически полностью остановил исследования на протяжении почти 20 лет.'\n",
            "'Erst in den 1980er Jahren begannen Elektrokonzerne wie die Siemens AG (Metal-Projekt) erneut mit der Forschung.' ---> 'Только в 1980-х годах электроконцерны, такие как Siemens AG (проект металлов), вновь начали исследования.'\n",
            "'Zu diesen Vorhaben zählt auch die Forschungsarbeit im Sonderforschungsbereich \"Elektronische Sprachforschung\" an der Universität des Saarlandes.' ---> 'Среди этих проектов - исследовательская работа в специальном исследовательском центре \"Электронные языковые исследования\" в Саарском университете.'\n",
            "'Hier wurde das System \"SUSY\" entwickelt, das in der Lage war, aus dem Deutschen und ins Deutsche zu übersetzen.[2] Ein weiteres System des Sonderforschungsbereichs war ASCOF, in dem neben morpho-syntaktischen auch semantische Informationen für die Übersetzung herangezogen wurden.[3] In der gleichen Zeit initiierte die japanische Regierung das Fünfte-Generation-Projekt, bei dem MÜ vom Englischen ins Japanische zunächst auf der Basis der Programmiersprache Prolog implementiert wurde.' ---> 'Здесь была разработана система \"SUSY\", которая была способна переводить с немецкого на немецкий язык.[2] Еще одной системой специального исследовательского направления была ASCOF, в которой помимо морфосинтаксической также семантическая информация была использована для перевода.[3] В то же время японское правительство инициировало проект пятого поколения, в котором МУ с английского на японский язык сначала был реализован на основе языка программирования Prolog.'\n",
            "'Die enge Zusammenarbeit zwischen Universitäten, Elektrokonzernen und Regierung führte zu den weltweit ersten kommerziellen MÜ-Programmen für PCs und hat Japan in die Führungsposition der MÜ-Forschung weltweit gebracht.' ---> 'Тесное сотрудничество между университетами, электротехническими компаниями и правительством привело к первым в мире коммерческим программам по исследованию ПК и сделало Японию лидером в области ПК в мире.'\n",
            "'In den 1990er Jahren lief in Deutschland das BMBF-Leitprojekt Verbmobil, dessen Ziel es war, deutsche, englische und japanische gesprochene Dialogsprache zu dolmetschen.' ---> 'В 1990-х годах в Германии работал ведущий проект BMBF Verbmobil, целью которого было перевод немецкого, английского и японского языков разговорного диалога.'\n",
            "'Das Verbmobil-System sollte gesprochene Spontansprache erkennen, die Eingabe analysieren, übersetzen, einen Satz erzeugen und ihn aussprechen.[4]' ---> 'Система Verbmobil должна была распознавать разговорный спонтанный язык, анализировать ввод, переводить, создавать предложение и произносить его.[4]'\n",
            "'In den 2000er Jahren kamen vermehrt statistische Verfahren zum Einsatz.' ---> 'В 2000-х годах стали использоваться все больше статистических методов.'\n",
            "'So bietet Google seit 2006 ein statistisches Übersetzungssystem an.[5] Auch regelbasierte Ansätze wurden weiterentwickelt.' ---> 'Так, с 2006 года Google предлагает статистическую систему перевода.[5] Также были разработаны подходы, основанные на правилах.'\n",
            "'Eines der bekanntesten Forschungsprojekte dieser Art ist die freie Software Apertium, die von der spanischen Regierung und der Regierung von Katalonien finanziert und an der Universität Alicante weiterentwickelt wird.' ---> 'Одним из самых известных исследовательских проектов такого рода является свободное программное обеспечение Apertium, финансируемое правительством Испании и правительством Каталонии и разрабатываемое в Университете Аликанте.'\n",
            "'Der Stand der MÜ im Jahr 2010 wurde von vielen Menschen als unbefriedigend bewertet.' ---> 'Состояние МР в 2010 году было оценено многими людьми как неудовлетворительное.'\n",
            "'Grundsätzlich versteht die Wissenschaft menschliche Sprache aber noch unzureichend.' ---> 'Но в принципе наука еще недостаточно понимает человеческий язык.'\n",
            "'Die meisten Sprachwissenschaftler gingen gar davon aus, dass maschineller Übersetzung ohne über das reine Sprachverständnis weit hinausgehende Kompetenzen automatischer Systeme grundsätzliche Grenzen gesetzt sind, da viele Übersetzungen zudem große Mengen an konzeptuellem Wissen, Metawissen sowie Kenntnisse über die Konstitution menschlicher Umwelt allgemein und über die Konventionen sozialer Interaktion erfordern.' ---> 'Большинство лингвистов даже полагали, что машинный перевод без компетенций автоматических систем, выходящих далеко за рамки чистого понимания языка, имеет фундаментальные ограничения, поскольку многие переводы также требуют больших объемов концептуальных знаний, метазнаний, а также знаний о конституции человеческой среды в целом и о конвенциях социального взаимодействия.'\n",
            "'Seit dem Jahr 2016 werden für Übersetzungsprogramme zunehmend künstliche neuronale Netze, d. h. künstliche Intelligenzen eingesetzt, wodurch der Fortschritt rasant zunahm.' ---> 'С 2016 года в переводе программ все чаще используются искусственные нейронные сети, т.е. искусственный интеллект, что привело к быстрому росту прогресса.'\n",
            "'Beispiele sind DeepL, Google Übersetzer, Yandex.Translate sowie der Bing Translator, die fortan deutlich bessere Ergebnisse erzielten.[6]' ---> 'Примеры: DeepL, Google Translator, Yandex.Translate, а также Bing Translator, которые с тех пор добились значительно лучших результатов.[6]'\n",
            "'Im März 2018 teilte Microsoft mit, durch eine KI Chinesisch-Englisch-Übersetzungen mit der Qualität eines professionellen menschlichen Übersetzers zu erreichen.' ---> 'В марте 2018 года Microsoft объявила, что через ИИ она достигнет качества профессионального человеческого переводчика в переводе с китайского на английский.'\n",
            "'Das sei ein Durchbruch bei der maschinellen Übersetzung, den Microsoft nicht so früh erwartet habe.[7][8]' ---> 'Это прорыв в машинном переводе, которого Microsoft не ожидала так рано.[7][8]'\n",
            "'Der Bedarf an MÜ-Anwendungen steigt weiter:' ---> 'Потребность в МУ продолжает расти:'\n",
            "'Viele Texte sind heute digital verfügbar (also leicht für den Computer zu verarbeiten).' ---> 'Многие тексты сегодня доступны в цифровом виде (то есть легко обрабатываются компьютером).'\n",
            "'Die Globalisierung erfordert die Übertragung von immer mehr Texten in immer mehr Sprachen (der Markt für Übersetzung verdoppelt sich alle vier Jahre), während die Popularität des Berufs des Übersetzers/Dolmetschers stagniert.' ---> 'Глобализация требует перевода все большего количества текстов на все больше языков (рынок переводов удваивается каждые четыре года), в то время как популярность профессии переводчика/переводчика стагнирует.'\n",
            "'Gerade von nur wenigen Westeuropäern/Amerikanern gesprochene beziehungsweise für diese schwierig zu erlernende Sprachen aus Regionen, deren Bewohner ihrerseits kaum westliche Sprachen sprechen, werden immer wichtiger:' ---> 'Особенно важными становятся языки, на которых говорят немногие западные европейцы/американцы, или языки, которые трудно изучать из регионов, жители которых в свою очередь мало говорят на западных языках:'\n",
            "'kommerziell wichtig: die ostasiatischen Sprachen Chinesisch, Koreanisch und Japanisch; sowie Thai.' ---> 'коммерчески важные: восточноазиатские языки китайский, корейский и японский; а также тайский.'\n",
            "'militärisch wichtig: Sprachen der internationalen Konfliktregionen, vor allem mit Beteiligung des US-Militärs.' ---> 'военно-значимые: языки регионов международных конфликтов, в частности, с участием американских военных.'\n",
            "'2003 haben gleich mehrere US-Software-Unternehmen Übersetzungsprogramme für Arabisch und Paschtu (eine der Sprachen in Afghanistan und Grenzregionen Pakistans) herausgebracht.' ---> 'В 2003 году несколько американских программных компаний выпустили программы для перевода на арабский и пашту (один из языков Афганистана и приграничных районов Пакистана).'\n",
            "'Ebenfalls 2003 hat die DARPA einen Blind-Wettbewerb für eine unbekannte Ausgangssprache durchgeführt.' ---> 'Также в 2003 году DARPA провела конкурс для слепых на неизвестный исходный язык.'\n",
            "'2011 wurde das BOLT-Programm gestartet, das zum Ziel hat, die Erforschung der Übersetzung chinesischer und arabischer Texte ins Englische zu fördern.[9][10]' ---> 'В 2011 году была запущена программа BOLT, целью которой является содействие исследованию перевода китайских и арабских текстов на английский язык.'\n"
          ]
        }
      ],
      "source": [
        "for s, t in zip(norm_texts, tgt_texts):\n",
        "  if len(s):\n",
        "    print(f\"{s!r} ---> {t['translation_text']!r}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
