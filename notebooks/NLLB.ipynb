{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrePankraz/speech_service/blob/main/notebooks/NLLB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aiz5wUyrg78V"
      },
      "source": [
        "## Translation - No Language Left Behind (NLLB)\n",
        "The following Notebook can translate text between 200 languages. It's based on the Meta model [NLLB](https://ai.facebook.com/research/no-language-left-behind/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAPChOdCghjA"
      },
      "source": [
        "# Set-up environment\n",
        "We need following packages:\n",
        "\n",
        "*   optional: accelerate and bitsandbytes for [8bit model inference](https://huggingface.co/blog/hf-bitsandbytes-integration)\n",
        "*   [transformers](https://github.com/huggingface/transformers) for NLLB model\n",
        "*   [sentence_cleaner_splitter](https://github.com/facebookresearch/LASER/tree/main/utils) from project [LASER](https://github.com/facebookresearch/LASER) for sentence splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgE5lQP7gYnC",
        "outputId": "32af3fd7-0885-4da6-f95c-1ad491764cba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# !pip install --quiet accelerate\n",
        "# !pip install --quiet bitsandbytes\n",
        "!pip install --quiet git+https://github.com/huggingface/transformers.git # Install latest version of transformers\n",
        "!pip install --quiet sentence_cleaner_splitter@git+https://github.com/facebookresearch/LASER.git#subdirectory=utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YB6DMVBExDFN"
      },
      "source": [
        "# Check GPU\n",
        "The following experiments can be run without a GPU, but it will take much longer!\n",
        "\n",
        "See Colab Menu: Runtime / Change type.\n",
        "\n",
        "Clean up dangling pointers and VRAM and check if GPU available:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfrJ_WjWxCUj",
        "outputId": "efa5c80a-690d-42b7-baf3-5f4e63456c1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Nov  9 19:20:14 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P0    28W /  70W |   3182MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "import gc\n",
        "import torch\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kB9JOBuQnULY"
      },
      "source": [
        "# Set-up AI-model for translation\n",
        "We need a pre-trained tokenizer and a model, that are downloaded from [Hugging Faces](https://huggingface.co/models?sort=downloads&search=facebook%2Fnllb). \n",
        "\n",
        "Multiple model sizes are available, to adapt to the GPU VRAM constraints. Only the big models provide enough quality, the smaller are just for quick tests.\n",
        "\n",
        "With the param `device_map='auto'` instead of `.cuda()` you can dynamically spread the model over GPUs / CPUs and load bigger models, but they are slower as inference time. See [accelerate](https://huggingface.co/docs/accelerate/usage_guides/big_modeling).\n",
        "\n",
        "With the param `load_in_8bit=True` you can also load bigger models, but they are slow at inference time and I also had inference bugs with NLLB. See [bitsandbytes](https://huggingface.co/blog/hf-bitsandbytes-integration).\n",
        "(This also doesn't always work: 'ERROR: Your GPU does not support Int8 Matmul!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cu04_XOCf0-c",
        "outputId": "03fd1637-592a-4f61-d324-72d06fbeb5da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of M2M100ForConditionalGeneration were not initialized from the model checkpoint at facebook/nllb-200-distilled-600M and are newly initialized: ['model.decoder.embed_positions.weights', 'model.encoder.embed_positions.weights']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, pipeline\n",
        "\n",
        "# Load model NLLB\n",
        "# facebook/nllb-200-distilled-600M, facebook/nllb-200-distilled-1.3B, facebook/nllb-200-3.3B\n",
        "# VRAM at least: 4 | 8 | 16 GB VRAM\n",
        "model_id = 'facebook/nllb-200-distilled-600M'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_id).cuda()\n",
        "\n",
        "model.device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIG7UBFLoQnq"
      },
      "source": [
        "A source and a target language are to be provided to the translation pipeline. The supported language IDs are visible with this map from project [LASER](https://github.com/facebookresearch/LASER), which has been used for NLLB training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSeWH1HakH8i",
        "outputId": "a8ae2c07-494a-4bdf-b737-0ffa48000c73"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ace_Arab': 'ace_Arab',\n",
              " 'ace_Latn': 'ace_Latn',\n",
              " 'acm_Arab': 'acm',\n",
              " 'acq_Arab': 'acq',\n",
              " 'aeb_Arab': 'aeb',\n",
              " 'afr_Latn': 'afr',\n",
              " 'ajp_Arab': 'ajp',\n",
              " 'aka_Latn': 'aka',\n",
              " 'amh_Ethi': 'amh',\n",
              " 'apc_Arab': 'apc',\n",
              " 'arb_Arab': 'ara_Arab',\n",
              " 'arb_Latn': 'ara_Latn',\n",
              " 'ars_Arab': 'ars',\n",
              " 'ary_Arab': 'ary',\n",
              " 'arz_Arab': 'arz',\n",
              " 'asm_Beng': 'asm',\n",
              " 'ast_Latn': 'ast',\n",
              " 'awa_Deva': 'awa',\n",
              " 'ayr_Latn': 'ayr',\n",
              " 'azb_Arab': 'azb',\n",
              " 'azj_Latn': 'azj',\n",
              " 'bak_Cyrl': 'bak',\n",
              " 'bam_Latn': 'bam',\n",
              " 'ban_Latn': 'ban',\n",
              " 'bel_Cyrl': 'bel',\n",
              " 'bem_Latn': 'bem',\n",
              " 'ben_Beng': 'ben',\n",
              " 'bho_Deva': 'bho',\n",
              " 'bjn_Arab': 'bjn_Arab',\n",
              " 'bjn_Latn': 'bjn_Latn',\n",
              " 'bod_Tibt': 'bod',\n",
              " 'bos_Latn': 'bos',\n",
              " 'bug_Latn': 'bug',\n",
              " 'bul_Cyrl': 'bul',\n",
              " 'cat_Latn': 'cat',\n",
              " 'ceb_Latn': 'ceb',\n",
              " 'ces_Latn': 'ces',\n",
              " 'cjk_Latn': 'cjk',\n",
              " 'ckb_Arab': 'ckb',\n",
              " 'crh_Latn': 'crh_Latn',\n",
              " 'cym_Latn': 'cym',\n",
              " 'dan_Latn': 'dan',\n",
              " 'deu_Latn': 'deu',\n",
              " 'dik_Latn': 'dik',\n",
              " 'diq_Latn': 'diq',\n",
              " 'dyu_Latn': 'dyu',\n",
              " 'dzo_Tibt': 'dzo',\n",
              " 'ell_Grek': 'ell',\n",
              " 'eng_Latn': 'eng',\n",
              " 'epo_Latn': 'epo',\n",
              " 'est_Latn': 'est',\n",
              " 'eus_Latn': 'eus',\n",
              " 'ewe_Latn': 'ewe',\n",
              " 'fao_Latn': 'fao',\n",
              " 'pes_Arab': 'fas',\n",
              " 'fij_Latn': 'fij',\n",
              " 'fin_Latn': 'fin',\n",
              " 'fon_Latn': 'fon',\n",
              " 'fra_Latn': 'fra',\n",
              " 'fur_Latn': 'fur',\n",
              " 'fuv_Latn': 'fuv',\n",
              " 'gla_Latn': 'gla',\n",
              " 'gle_Latn': 'gle',\n",
              " 'glg_Latn': 'glg',\n",
              " 'grn_Latn': 'grn',\n",
              " 'guj_Gujr': 'guj',\n",
              " 'hat_Latn': 'hat',\n",
              " 'hau_Latn': 'hau',\n",
              " 'heb_Hebr': 'heb',\n",
              " 'hin_Deva': 'hin',\n",
              " 'hne_Deva': 'hne',\n",
              " 'hrv_Latn': 'hrv',\n",
              " 'hun_Latn': 'hun',\n",
              " 'hye_Armn': 'hye',\n",
              " 'ibo_Latn': 'ibo',\n",
              " 'ilo_Latn': 'ilo',\n",
              " 'ind_Latn': 'ind',\n",
              " 'isl_Latn': 'isl',\n",
              " 'ita_Latn': 'ita',\n",
              " 'jav_Latn': 'jav',\n",
              " 'jpn_Jpan': 'jpn',\n",
              " 'kab_Latn': 'kab',\n",
              " 'kac_Latn': 'kac',\n",
              " 'kam_Latn': 'kam',\n",
              " 'kan_Knda': 'kan',\n",
              " 'kas_Arab': 'kas_Arab',\n",
              " 'kas_Deva': 'kas_Deva',\n",
              " 'kat_Geor': 'kat',\n",
              " 'knc_Arab': 'kau_Arab',\n",
              " 'knc_Latn': 'kau_Latn',\n",
              " 'kaz_Cyrl': 'kaz',\n",
              " 'kbp_Latn': 'kbp',\n",
              " 'kea_Latn': 'kea',\n",
              " 'khm_Khmr': 'khm',\n",
              " 'kik_Latn': 'kik',\n",
              " 'kin_Latn': 'kin',\n",
              " 'kir_Cyrl': 'kir',\n",
              " 'kmb_Latn': 'kmb',\n",
              " 'kon_Latn': 'kon',\n",
              " 'kor_Hang': 'kor',\n",
              " 'kmr_Latn': 'kur',\n",
              " 'lao_Laoo': 'lao',\n",
              " 'lvs_Latn': 'lav',\n",
              " 'lij_Latn': 'lij',\n",
              " 'lim_Latn': 'lim',\n",
              " 'lin_Latn': 'lin',\n",
              " 'lit_Latn': 'lit',\n",
              " 'lmo_Latn': 'lmo',\n",
              " 'ltg_Latn': 'ltg',\n",
              " 'ltz_Latn': 'ltz',\n",
              " 'lua_Latn': 'lua',\n",
              " 'lug_Latn': 'lug',\n",
              " 'luo_Latn': 'luo',\n",
              " 'lus_Latn': 'lus',\n",
              " 'mag_Deva': 'mag',\n",
              " 'mai_Deva': 'mai',\n",
              " 'mal_Mlym': 'mal',\n",
              " 'mar_Deva': 'mar',\n",
              " 'min_Arab': 'min_Arab',\n",
              " 'min_Latn': 'min_Latn',\n",
              " 'mkd_Cyrl': 'mkd',\n",
              " 'plt_Latn': 'mlg',\n",
              " 'mlt_Latn': 'mlt',\n",
              " 'khk_Cyrl': 'mon',\n",
              " 'mos_Latn': 'mos',\n",
              " 'mri_Latn': 'mri',\n",
              " 'zsm_Latn': 'msa',\n",
              " 'mya_Mymr': 'mya',\n",
              " 'nld_Latn': 'nld',\n",
              " 'nno_Latn': 'nno',\n",
              " 'nob_Latn': 'nob',\n",
              " 'npi_Deva': 'npi',\n",
              " 'nso_Latn': 'nso',\n",
              " 'nus_Latn': 'nus',\n",
              " 'nya_Latn': 'nya',\n",
              " 'oci_Latn': 'oci',\n",
              " 'gaz_Latn': 'orm',\n",
              " 'ory_Orya': 'ory',\n",
              " 'pag_Latn': 'pag',\n",
              " 'pan_Guru': 'pan',\n",
              " 'pap_Latn': 'pap',\n",
              " 'pol_Latn': 'pol',\n",
              " 'por_Latn': 'por',\n",
              " 'prs_Arab': 'prs',\n",
              " 'pbt_Arab': 'pus',\n",
              " 'quy_Latn': 'que',\n",
              " 'ron_Latn': 'ron',\n",
              " 'run_Latn': 'run',\n",
              " 'rus_Cyrl': 'rus',\n",
              " 'sag_Latn': 'sag',\n",
              " 'san_Deva': 'san',\n",
              " 'sat_Olck': 'sat',\n",
              " 'scn_Latn': 'scn',\n",
              " 'shn_Mymr': 'shn',\n",
              " 'sin_Sinh': 'sin',\n",
              " 'slk_Latn': 'slk',\n",
              " 'slv_Latn': 'slv',\n",
              " 'smo_Latn': 'smo',\n",
              " 'sna_Latn': 'sna',\n",
              " 'snd_Arab': 'snd',\n",
              " 'som_Latn': 'som',\n",
              " 'sot_Latn': 'sot',\n",
              " 'spa_Latn': 'spa',\n",
              " 'als_Latn': 'sqi',\n",
              " 'srd_Latn': 'srd',\n",
              " 'srp_Cyrl': 'srp_Cyrl',\n",
              " 'ssw_Latn': 'ssw',\n",
              " 'sun_Latn': 'sun',\n",
              " 'swe_Latn': 'swe',\n",
              " 'swh_Latn': 'swh',\n",
              " 'szl_Latn': 'szl',\n",
              " 'tam_Taml': 'tam',\n",
              " 'tat_Cyrl': 'tat_Cyrl',\n",
              " 'tel_Telu': 'tel',\n",
              " 'tgk_Cyrl': 'tgk',\n",
              " 'tgl_Latn': 'tgl',\n",
              " 'tha_Thai': 'tha',\n",
              " 'tir_Ethi': 'tir',\n",
              " 'taq_Latn': 'tmh_Latn',\n",
              " 'taq_Tfng': 'tmh_Tfng',\n",
              " 'ton_Latn': 'ton',\n",
              " 'tpi_Latn': 'tpi',\n",
              " 'tsn_Latn': 'tsn',\n",
              " 'tso_Latn': 'tso',\n",
              " 'tuk_Latn': 'tuk',\n",
              " 'tum_Latn': 'tum',\n",
              " 'tur_Latn': 'tur',\n",
              " 'twi_Latn': 'twi',\n",
              " 'tzm_Tfng': 'tzm',\n",
              " 'uig_Arab': 'uig',\n",
              " 'ukr_Cyrl': 'ukr',\n",
              " 'umb_Latn': 'umb',\n",
              " 'urd_Arab': 'urd',\n",
              " 'uzn_Latn': 'uzb',\n",
              " 'vec_Latn': 'vec',\n",
              " 'vie_Latn': 'vie',\n",
              " 'war_Latn': 'war',\n",
              " 'wol_Latn': 'wol',\n",
              " 'xho_Latn': 'xho',\n",
              " 'ydd_Hebr': 'yid',\n",
              " 'yor_Latn': 'yor',\n",
              " 'yue_Hant': 'yue',\n",
              " 'zho_Hans': 'zho_Hans',\n",
              " 'zho_Hant': 'zho_Hant',\n",
              " 'zul_Latn': 'zul'}"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ],
      "source": [
        "# Optional output...\n",
        "from sentence_cleaner_splitter.sentence_split import split_lang_code_map\n",
        "\n",
        "split_lang_code_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "ranNVALqs0gj"
      },
      "outputs": [],
      "source": [
        "src_lang='deu_Latn'\n",
        "tgt_lang='rus_Cyrl'\n",
        "\n",
        "src_text = '''\n",
        "Menschheitstraum\n",
        "Das Verstehen einer Sprache, ohne sie gelernt zu haben, ist ein alter Menschheitstraum (Turmbau zu Babel, J. Bechers numerische Interlingua, Timerio, Babelfisch, Pfingstwunder, Science-Fiction-Geschichten). Die Erfindung der Computer in Kombination mit der Beschäftigung mit dem Phänomen Sprache als wissenschaftliche Disziplin (Sprachwissenschaft) hat zum ersten Mal einen konkreten Weg zur Erfüllung dieses Traums geöffnet.\n",
        "\n",
        "Geschichte\n",
        "Bis zum heutigen Tag hat das militärische Interesse den Weg der MÜ entscheidend geprägt. Eines der frühesten Projekte war ein Russisch-Englisch-Übersetzungsprogramm für das US-Militär. Trotz seiner anekdotenhaft schlechten Qualität genoss das Programm hohe Popularität unter US-Militärs, die sich zum ersten Mal ohne den Umweg über Dritte (Dolmetscher und Übersetzer) selbst zumindest einen Eindruck vom Inhalt russischer Dokumente verschaffen konnten.\n",
        "\n",
        "Der 1966 für das Verteidigungsministerium der Vereinigten Staaten erstellte ALPAC-Bericht[1] bescheinigte der MÜ grundsätzliche Unrealisierbarkeit und brachte mit einem Schlag die Forschung für fast 20 Jahre praktisch ganz zum Erliegen. Erst in den 1980er Jahren begannen Elektrokonzerne wie die Siemens AG (Metal-Projekt) erneut mit der Forschung. Zu diesen Vorhaben zählt auch die Forschungsarbeit im Sonderforschungsbereich „Elektronische Sprachforschung“ an der Universität des Saarlandes. Hier wurde das System „SUSY“ entwickelt, das in der Lage war, aus dem Deutschen und ins Deutsche zu übersetzen.[2] Ein weiteres System des Sonderforschungsbereichs war ASCOF, in dem neben morpho-syntaktischen auch semantische Informationen für die Übersetzung herangezogen wurden.[3] In der gleichen Zeit initiierte die japanische Regierung das Fünfte-Generation-Projekt, bei dem MÜ vom Englischen ins Japanische zunächst auf der Basis der Programmiersprache Prolog implementiert wurde. Die enge Zusammenarbeit zwischen Universitäten, Elektrokonzernen und Regierung führte zu den weltweit ersten kommerziellen MÜ-Programmen für PCs und hat Japan in die Führungsposition der MÜ-Forschung weltweit gebracht. In den 1990er Jahren lief in Deutschland das BMBF-Leitprojekt Verbmobil, dessen Ziel es war, deutsche, englische und japanische gesprochene Dialogsprache zu dolmetschen. Das Verbmobil-System sollte gesprochene Spontansprache erkennen, die Eingabe analysieren, übersetzen, einen Satz erzeugen und ihn aussprechen.[4]\n",
        "\n",
        "In den 2000er Jahren kamen vermehrt statistische Verfahren zum Einsatz. So bietet Google seit 2006 ein statistisches Übersetzungssystem an.[5] Auch regelbasierte Ansätze wurden weiterentwickelt. Eines der bekanntesten Forschungsprojekte dieser Art ist die freie Software Apertium, die von der spanischen Regierung und der Regierung von Katalonien finanziert und an der Universität Alicante weiterentwickelt wird.\n",
        "\n",
        "Der Stand der MÜ im Jahr 2010 wurde von vielen Menschen als unbefriedigend bewertet. Grundsätzlich versteht die Wissenschaft menschliche Sprache aber noch unzureichend. Die meisten Sprachwissenschaftler gingen gar davon aus, dass maschineller Übersetzung ohne über das reine Sprachverständnis weit hinausgehende Kompetenzen automatischer Systeme grundsätzliche Grenzen gesetzt sind, da viele Übersetzungen zudem große Mengen an konzeptuellem Wissen, Metawissen sowie Kenntnisse über die Konstitution menschlicher Umwelt allgemein und über die Konventionen sozialer Interaktion erfordern.\n",
        "\n",
        "Seit dem Jahr 2016 werden für Übersetzungsprogramme zunehmend künstliche neuronale Netze, d. h. künstliche Intelligenzen eingesetzt, wodurch der Fortschritt rasant zunahm. Beispiele sind DeepL, Google Übersetzer, Yandex.Translate sowie der Bing Translator, die fortan deutlich bessere Ergebnisse erzielten.[6]\n",
        "\n",
        "Im März 2018 teilte Microsoft mit, durch eine KI Chinesisch-Englisch-Übersetzungen mit der Qualität eines professionellen menschlichen Übersetzers zu erreichen. Das sei ein Durchbruch bei der maschinellen Übersetzung, den Microsoft nicht so früh erwartet habe.[7][8]\n",
        "\n",
        "Der Bedarf an MÜ-Anwendungen steigt weiter:\n",
        "\n",
        "Viele Texte sind heute digital verfügbar (also leicht für den Computer zu verarbeiten).\n",
        "Die Globalisierung erfordert die Übertragung von immer mehr Texten in immer mehr Sprachen (der Markt für Übersetzung verdoppelt sich alle vier Jahre), während die Popularität des Berufs des Übersetzers/Dolmetschers stagniert.\n",
        "Gerade von nur wenigen Westeuropäern/Amerikanern gesprochene beziehungsweise für diese schwierig zu erlernende Sprachen aus Regionen, deren Bewohner ihrerseits kaum westliche Sprachen sprechen, werden immer wichtiger:\n",
        "kommerziell wichtig: die ostasiatischen Sprachen Chinesisch, Koreanisch und Japanisch; sowie Thai.\n",
        "militärisch wichtig: Sprachen der internationalen Konfliktregionen, vor allem mit Beteiligung des US-Militärs. 2003 haben gleich mehrere US-Software-Unternehmen Übersetzungsprogramme für Arabisch und Paschtu (eine der Sprachen in Afghanistan und Grenzregionen Pakistans) herausgebracht. Ebenfalls 2003 hat die DARPA einen Blind-Wettbewerb für eine unbekannte Ausgangssprache durchgeführt. 2011 wurde das BOLT-Programm gestartet, das zum Ziel hat, die Erforschung der Übersetzung chinesischer und arabischer Texte ins Englische zu fördern.[9][10]\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czIDeF0no0yB"
      },
      "source": [
        "# Set-up translation pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "sZ3IvcEnf1zx"
      },
      "outputs": [],
      "source": [
        "translation_pipeline = pipeline('translation',\n",
        "                                model=model,\n",
        "                                tokenizer=tokenizer,\n",
        "                                device=model.device,\n",
        "                                src_lang=src_lang,\n",
        "                                tgt_lang=tgt_lang,\n",
        "                                max_length=512,\n",
        "                                batch_size=16,\n",
        "                                # beam search with early stopping, better than greedy:\n",
        "                                num_beams=3,\n",
        "                                early_stopping=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCZ7Yb4SptVg"
      },
      "source": [
        "# First Translation Test\n",
        "Very long sequences will run into the following problems:\n",
        "*    'Token indices sequence length is longer than the specified maximum sequence length for this model (1320 > 1024).'\n",
        "*    'Your input_length: 1320 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)'\n",
        "\n",
        "The model is trained on sentence level and problems are possible with longer sequences. So it's a good idea to split the text.\n",
        "\n",
        "See paper: 'The maximum sequence length during training is 512 for both the encoder and the decoder.'\n",
        "\n",
        "The model is restricted to 512 tokens, which means less than 500 words! Text documents should be split into sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlOGWyS0po0n",
        "outputId": "560b4aeb-84be-4845-a4c7-777129fb4193"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your input_length: 1320 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'translation_text': 'Человеческая мечта Понимание языка, не изучая его, также открыло для себя впервые конкретный путь к достижению этой мечты. История современного общества требует все большего военного интереса к китайскому языку (цифровая интерлингва, Тимерио, Бабелфиш, Пингвин-Транс, история научной фантастики). Создание компьютеров в сочетании с использованием феномена языка в качестве научной дисциплины (языковая наука) впервые открыло для себя конкретный путь к достижению этой мечты. История современного общества требует все большего военного интереса к китайскому языку. Один из первых проектов, созданных для изучения английского языка для американских жителей, был разработан в течение многих лет. Несмотря на практические результаты исследований в области английского языка, а также исследования в области изучения английского языка, проект \"Бингвин-Транс-Транс-Транс-Транс-Транс-Транс-Транс-Транс-Пренс-Транс-Транс-Транс-Транс-Транс-Пренс-Транс-Транс-Пренс-Транс-Транс-Транс-Пренс-Транс-Транс-Транс-Пренс-Транс-Транс-Транс-Транс-Транс-Транс-Транс-Транс-Транс-Транс-Транс-Транс-Транс-Транс-Транс-Транс-Транс-Транс-Транс-Транс-Транс-Транс-Транс-Транс-Транс-Транс-Транс-Транс-Транс-Транс-Транс-Транс-Транс-Транс-Транс-Транс-Транс-Транс-Транс-Транс-Транс-Транс-Транс-Транс-Т'}]"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ],
      "source": [
        "translation_pipeline(src_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmiA27zwvIpJ"
      },
      "source": [
        "# Set-up Sentence Splitter\n",
        "Use sentence splitter form project [LASER](https://github.com/facebookresearch/LASER), which has been used for NLLB training. This is a small AI-model, which will be downloaded in the background. Splitting sentences for 200 languages is much harder than a Regexp..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "h0Vr6f9psxXy"
      },
      "outputs": [],
      "source": [
        "from sentence_cleaner_splitter.cleaner_splitter import SentenceSplitClean\n",
        "\n",
        "sentence_splitter = SentenceSplitClean(src_lang, 'default')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJw5ZBaTvfFV"
      },
      "source": [
        "# Split text into sentences\n",
        "Replace or remove some special chars like zero-width spaces or non-breaking spaces. The NLLB model doesn't understand them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "oHMFT2jDtc5e"
      },
      "outputs": [],
      "source": [
        "norm_texts = []\n",
        "for _, _, line in sentence_splitter(src_text.replace('\\u200b', ' ')):\n",
        "    norm_texts.append(line.strip())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BOHYWbEwNLY"
      },
      "source": [
        "# Translate Sentences\n",
        "Attention: The NLLB model doesn't always map empty lines to empty lines in other languages! This seems to be a bug in the model? We have to postprocess this or insert a different input token for empty lines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTKjrZ82tqUN",
        "outputId": "212b4756-6ba0-42cd-b6e5-302acf716fe0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Мечта человечества',\n",
              " 'Понимание языка, не изучая его, - это древняя мечта человечества (Строительство Вавилонской башни, Цифровая интерлингва Дж. Бекера, Тимерьо, Вавилонская рыба, Пингвинские чудеса, научные фантастики).',\n",
              " 'Изобретение компьютеров в сочетании с изучением языка как научной дисциплины (лингвистика) впервые открыло конкретный путь к осуществлению этой мечты.',\n",
              " 'С другой стороны:',\n",
              " 'История',\n",
              " 'На сегодняшний день военные интересы определяют путь МУ.',\n",
              " 'Одним из самых ранних проектов была программа перевода на русско-английский язык для американских военных.',\n",
              " 'Несмотря на плохое анекдотное качество, программа была очень популярна среди военнослужащих США, которые впервые смогли получить, по крайней мере, собственное представление о содержании российских документов без использования третьих лиц (переводчиков и переводчиков).',\n",
              " 'С другой стороны:',\n",
              " 'Отчет ALPAC, подготовленный в 1966 году для Министерства обороны Соединенных Штатов[1], подтвердил, что МУ в принципе нереалистична, и в одно мгновение ока оказал практически полный конец исследованиям в течение почти 20 лет.',\n",
              " 'Только в 1980-х годах электроконцерны, такие как Siemens AG (металлический проект), возобновили исследования.',\n",
              " 'К этим проектам относится и исследовательская работа в специальном исследовательском отделе \"Электронные языковые исследования\" в Университете Саарленда.',\n",
              " 'Здесь была разработана система \"SUSY\", которая была способна переводить из немецкого и на немецкий язык.[2] Еще одной системой специальной области исследований была ASCOF, в которой помимо морфо-синтактической, также использовалась семантическая информация для перевода.[3] В то же время японское правительство инициировало пятое поколение проекта, в котором МУ из английского в японский был внедрен сначала на основе программирования Prolog.',\n",
              " 'Тесное сотрудничество между университетами, электрокомпаниями и правительством привело к созданию первых в мире коммерческих программ для ПК и выдвинуло Японию на лидирующее место в исследованиях в области ПК в мире.',\n",
              " 'В 1990-х годах в Германии велся руководящий проект BMBF Verbmobil, целью которого было толковать немецкий, английский и японский языки диалога.',\n",
              " 'Система Verbmobil должна распознавать разговорный спонтанный язык, анализировать ввод, переводить, создавать предложение и произносить его.[4]',\n",
              " 'С другой стороны:',\n",
              " 'В 2000-х годах стали применяться все больше статистических методов.',\n",
              " 'Так, с 2006 года Google предлагает статистическую систему перевода.[5] Также были разработаны подходы, основанные на правилах.',\n",
              " 'Одним из самых известных исследовательских проектов такого рода является свободный программный продукт Apertium, финансируемый испанским правительством и правительством Каталонии и разрабатываемый в Университете Аликанте.',\n",
              " 'С другой стороны:',\n",
              " 'По состоянию МУ в 2010 году многие считали неудовлетворительным.',\n",
              " 'Но, по сути, наука еще недостаточно понимает человеческий язык.',\n",
              " 'Большинство лингвистов полагали, что машинный перевод, не имея знаний, выходящих за рамки простого понимания языка, имеет принципиальные ограничения, поскольку многие переводы также требуют больших объемов концептуальных знаний, метазнаний, а также знаний о конституции человеческой среды в целом и о конвенциях социального взаимодействия.',\n",
              " 'С другой стороны:',\n",
              " 'С 2016 года в переводных программах все больше используются искусственные нейронные сети, то есть искусственный интеллект, что приводит к быстрому росту прогресса.',\n",
              " 'Примерами являются DeepL, Google Translator, Yandex.Translate и Bing Translator, которые получили значительно лучшие результаты.[6]',\n",
              " 'С другой стороны:',\n",
              " 'В марте 2018 года Microsoft объявила о том, что с помощью искусственного интеллекта достигнет китайско-английских переводов с качеством профессионального человеческого переводчика.',\n",
              " 'Это был прорыв в машинном переводе, который Microsoft не ожидала так рано.[7][8]',\n",
              " 'С другой стороны:',\n",
              " 'Потребность в МО применений продолжает расти:',\n",
              " 'С другой стороны:',\n",
              " 'Сегодня многие тексты доступны в цифровом виде (то есть легко обрабатываться на компьютере).',\n",
              " 'Глобализация требует перевода все большего количества текстов на все большее количество языков (рынок перевода удваивается каждые четыре года), в то время как популярность профессии переводчика / переводчика стагнирует.',\n",
              " 'Языки, которые говорят лишь немногие западноевропейцы/американцы, или языки, которые трудно выучить, из регионов, жители которых, в свою очередь, редко говорят западные языки, становятся все более важными:',\n",
              " 'Коммерчески важные: китайский, корейский и японский, а также тайский.',\n",
              " 'Военно важно: языки международных конфликтных регионов, особенно с участием американских военных.',\n",
              " 'В 2003 году несколько американских программных компаний выпустили программы перевода на арабский и пашту (один из языков Афганистана и пограничных регионов Пакистана).',\n",
              " 'Также в 2003 году DARPA провела конкурс на изучение неизвестного языка.',\n",
              " 'В 2011 году была запущена программа BOLT, которая направлена на содействие исследованию перевода китайских и арабских текстов на английский язык.[9][10]']"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ],
      "source": [
        "tgt_texts = translation_pipeline(norm_texts)\n",
        "tgt_texts = [t['translation_text'] for t in tgt_texts]\n",
        "\n",
        "tgt_texts"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Without Pipeline\n",
        "As alternative to pipelines, we can also use lower level functions for inference.\n",
        "\n",
        "(With larger batch and beam sizes we get into VRAM problems really fast with the current HuggingFaces implementation!)"
      ],
      "metadata": {
        "id": "xYd57PIR4-bl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.src_lang = src_lang\n",
        "batch_size = 8\n",
        "tgt_texts = []\n",
        "with torch.inference_mode():\n",
        "  for i in range(0, len(norm_texts), batch_size):\n",
        "    encoding = tokenizer(\n",
        "      norm_texts[i:i+batch_size],\n",
        "      truncation=True,\n",
        "      padding=True,\n",
        "      return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    translated_tokens = model.generate(\n",
        "        **encoding,\n",
        "        forced_bos_token_id=tokenizer.lang_code_to_id[tgt_lang],\n",
        "        max_length=512,\n",
        "        # beam search with early stopping, better than greedy:\n",
        "        num_beams=3, \n",
        "        early_stopping=True)\n",
        "    tgt_texts += tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)\n",
        "\n",
        "tgt_texts"
      ],
      "metadata": {
        "id": "8DpC-id9A706",
        "outputId": "f729b1d7-f1c2-4c8e-fd62-1f43d10c4779",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Мечта человечества',\n",
              " 'Понимание языка, не изучая его, - это древняя мечта человечества (Строительство Вавилонской башни, Цифровая интерлингва Дж. Бекера, Тимерьо, Вавилонская рыба, Пингвинские чудеса, научные фантастики).',\n",
              " 'Изобретение компьютеров в сочетании с изучением языка как научной дисциплины (лингвистика) впервые открыло конкретный путь к осуществлению этой мечты.',\n",
              " 'С другой стороны:',\n",
              " 'История',\n",
              " 'На сегодняшний день военные интересы определяют путь МУ.',\n",
              " 'Одним из самых ранних проектов была программа перевода на русско-английский язык для американских военных.',\n",
              " 'Несмотря на плохое анекдотное качество, программа была очень популярна среди военнослужащих США, которые впервые смогли получить, по крайней мере, собственное представление о содержании российских документов без использования третьих лиц (переводчиков и переводчиков).',\n",
              " 'С другой стороны:',\n",
              " 'Отчет ALPAC, подготовленный в 1966 году для Министерства обороны Соединенных Штатов[1], подтвердил, что МУ в принципе нереалистична, и в одно мгновение ока оказал практически полный конец исследованиям в течение почти 20 лет.',\n",
              " 'Только в 1980-х годах электроконцерны, такие как Siemens AG (металлический проект), возобновили исследования.',\n",
              " 'К этим проектам относится и исследовательская работа в специальном исследовательском отделе \"Электронные языковые исследования\" в Университете Саарленда.',\n",
              " 'Здесь была разработана система \"SUSY\", которая была способна переводить из немецкого и на немецкий язык.[2] Еще одной системой специальной области исследований была ASCOF, в которой помимо морфо-синтактической, также использовалась семантическая информация для перевода.[3] В то же время японское правительство инициировало пятое поколение проекта, в котором МУ из английского в японский был внедрен сначала на основе программирования Prolog.',\n",
              " 'Тесное сотрудничество между университетами, электрокомпаниями и правительством привело к созданию первых в мире коммерческих программ для ПК и выдвинуло Японию на лидирующее место в исследованиях в области ПК в мире.',\n",
              " 'В 1990-х годах в Германии велся руководящий проект BMBF Verbmobil, целью которого было толковать немецкий, английский и японский языки диалога.',\n",
              " 'Система Verbmobil должна распознавать разговорный спонтанный язык, анализировать ввод, переводить, создавать предложение и произносить его.[4]',\n",
              " 'С другой стороны:',\n",
              " 'В 2000-х годах стали применяться все больше статистических методов.',\n",
              " 'Так, с 2006 года Google предлагает статистическую систему перевода.[5] Также были разработаны подходы, основанные на правилах.',\n",
              " 'Одним из самых известных исследовательских проектов такого рода является свободный программный продукт Apertium, финансируемый испанским правительством и правительством Каталонии и разрабатываемый в Университете Аликанте.',\n",
              " 'С другой стороны:',\n",
              " 'По состоянию МУ в 2010 году многие считали неудовлетворительным.',\n",
              " 'Но, по сути, наука еще недостаточно понимает человеческий язык.',\n",
              " 'Большинство лингвистов полагали, что машинный перевод, не имея знаний, выходящих за рамки простого понимания языка, имеет принципиальные ограничения, поскольку многие переводы также требуют больших объемов концептуальных знаний, метазнаний, а также знаний о конституции человеческой среды в целом и о конвенциях социального взаимодействия.',\n",
              " 'С другой стороны:',\n",
              " 'С 2016 года в переводных программах все больше используются искусственные нейронные сети, то есть искусственный интеллект, что приводит к быстрому росту прогресса.',\n",
              " 'Примерами являются DeepL, Google Translator, Yandex.Translate и Bing Translator, которые получили значительно лучшие результаты.[6]',\n",
              " 'С другой стороны:',\n",
              " 'В марте 2018 года Microsoft объявила о том, что с помощью искусственного интеллекта достигнет китайско-английских переводов с качеством профессионального человеческого переводчика.',\n",
              " 'Это был прорыв в машинном переводе, который Microsoft не ожидала так рано.[7][8]',\n",
              " 'С другой стороны:',\n",
              " 'Потребность в МО применений продолжает расти:',\n",
              " 'С другой стороны:',\n",
              " 'Сегодня многие тексты доступны в цифровом виде (то есть легко обрабатываться на компьютере).',\n",
              " 'Глобализация требует перевода все большего количества текстов на все большее количество языков (рынок перевода удваивается каждые четыре года), в то время как популярность профессии переводчика / переводчика стагнирует.',\n",
              " 'Языки, которые говорят лишь немногие западноевропейцы/американцы, или языки, которые трудно выучить, из регионов, жители которых, в свою очередь, редко говорят западные языки, становятся все более важными:',\n",
              " 'Коммерчески важные: китайский, корейский и японский, а также тайский.',\n",
              " 'Военно важно: языки международных конфликтных регионов, особенно с участием американских военных.',\n",
              " 'В 2003 году несколько американских программных компаний выпустили программы перевода на арабский и пашту (один из языков Афганистана и пограничных регионов Пакистана).',\n",
              " 'Также в 2003 году DARPA провела конкурс на изучение неизвестного языка.',\n",
              " 'В 2011 году была запущена программа BOLT, которая направлена на содействие исследованию перевода китайских и арабских текстов на английский язык.[9][10]']"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "empVi_QSwRU9"
      },
      "source": [
        "# Show sentences and their matching translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiSzYqpsuS7Q",
        "outputId": "4f683dd4-ea4f-4117-b01e-e7535aebc31c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Menschheitstraum' ---> 'Мечта человечества'\n",
            "'Das Verstehen einer Sprache, ohne sie gelernt zu haben, ist ein alter Menschheitstraum (Turmbau zu Babel, J. Bechers numerische Interlingua, Timerio, Babelfisch, Pfingstwunder, Science-Fiction-Geschichten).' ---> 'Понимание языка, не изучая его, - это древняя мечта человечества (Строительство Вавилонской башни, Цифровая интерлингва Дж. Бекера, Тимерьо, Вавилонская рыба, Пингвинские чудеса, научные фантастики).'\n",
            "'Die Erfindung der Computer in Kombination mit der Beschäftigung mit dem Phänomen Sprache als wissenschaftliche Disziplin (Sprachwissenschaft) hat zum ersten Mal einen konkreten Weg zur Erfüllung dieses Traums geöffnet.' ---> 'Изобретение компьютеров в сочетании с изучением языка как научной дисциплины (лингвистика) впервые открыло конкретный путь к осуществлению этой мечты.'\n",
            "'Geschichte' ---> 'История'\n",
            "'Bis zum heutigen Tag hat das militärische Interesse den Weg der MÜ entscheidend geprägt.' ---> 'На сегодняшний день военные интересы определяют путь МУ.'\n",
            "'Eines der frühesten Projekte war ein Russisch-Englisch-Übersetzungsprogramm für das US-Militär.' ---> 'Одним из самых ранних проектов была программа перевода на русско-английский язык для американских военных.'\n",
            "'Trotz seiner anekdotenhaft schlechten Qualität genoss das Programm hohe Popularität unter US-Militärs, die sich zum ersten Mal ohne den Umweg über Dritte (Dolmetscher und Übersetzer) selbst zumindest einen Eindruck vom Inhalt russischer Dokumente verschaffen konnten.' ---> 'Несмотря на плохое анекдотное качество, программа была очень популярна среди военнослужащих США, которые впервые смогли получить, по крайней мере, собственное представление о содержании российских документов без использования третьих лиц (переводчиков и переводчиков).'\n",
            "'Der 1966 für das Verteidigungsministerium der Vereinigten Staaten erstellte ALPAC-Bericht[1] bescheinigte der MÜ grundsätzliche Unrealisierbarkeit und brachte mit einem Schlag die Forschung für fast 20 Jahre praktisch ganz zum Erliegen.' ---> 'Отчет ALPAC, подготовленный в 1966 году для Министерства обороны Соединенных Штатов[1], подтвердил, что МУ в принципе нереалистична, и в одно мгновение ока оказал практически полный конец исследованиям в течение почти 20 лет.'\n",
            "'Erst in den 1980er Jahren begannen Elektrokonzerne wie die Siemens AG (Metal-Projekt) erneut mit der Forschung.' ---> 'Только в 1980-х годах электроконцерны, такие как Siemens AG (металлический проект), возобновили исследования.'\n",
            "'Zu diesen Vorhaben zählt auch die Forschungsarbeit im Sonderforschungsbereich \"Elektronische Sprachforschung\" an der Universität des Saarlandes.' ---> 'К этим проектам относится и исследовательская работа в специальном исследовательском отделе \"Электронные языковые исследования\" в Университете Саарленда.'\n",
            "'Hier wurde das System \"SUSY\" entwickelt, das in der Lage war, aus dem Deutschen und ins Deutsche zu übersetzen.[2] Ein weiteres System des Sonderforschungsbereichs war ASCOF, in dem neben morpho-syntaktischen auch semantische Informationen für die Übersetzung herangezogen wurden.[3] In der gleichen Zeit initiierte die japanische Regierung das Fünfte-Generation-Projekt, bei dem MÜ vom Englischen ins Japanische zunächst auf der Basis der Programmiersprache Prolog implementiert wurde.' ---> 'Здесь была разработана система \"SUSY\", которая была способна переводить из немецкого и на немецкий язык.[2] Еще одной системой специальной области исследований была ASCOF, в которой помимо морфо-синтактической, также использовалась семантическая информация для перевода.[3] В то же время японское правительство инициировало пятое поколение проекта, в котором МУ из английского в японский был внедрен сначала на основе программирования Prolog.'\n",
            "'Die enge Zusammenarbeit zwischen Universitäten, Elektrokonzernen und Regierung führte zu den weltweit ersten kommerziellen MÜ-Programmen für PCs und hat Japan in die Führungsposition der MÜ-Forschung weltweit gebracht.' ---> 'Тесное сотрудничество между университетами, электрокомпаниями и правительством привело к созданию первых в мире коммерческих программ для ПК и выдвинуло Японию на лидирующее место в исследованиях в области ПК в мире.'\n",
            "'In den 1990er Jahren lief in Deutschland das BMBF-Leitprojekt Verbmobil, dessen Ziel es war, deutsche, englische und japanische gesprochene Dialogsprache zu dolmetschen.' ---> 'В 1990-х годах в Германии велся руководящий проект BMBF Verbmobil, целью которого было толковать немецкий, английский и японский языки диалога.'\n",
            "'Das Verbmobil-System sollte gesprochene Spontansprache erkennen, die Eingabe analysieren, übersetzen, einen Satz erzeugen und ihn aussprechen.[4]' ---> 'Система Verbmobil должна распознавать разговорный спонтанный язык, анализировать ввод, переводить, создавать предложение и произносить его.[4]'\n",
            "'In den 2000er Jahren kamen vermehrt statistische Verfahren zum Einsatz.' ---> 'В 2000-х годах стали применяться все больше статистических методов.'\n",
            "'So bietet Google seit 2006 ein statistisches Übersetzungssystem an.[5] Auch regelbasierte Ansätze wurden weiterentwickelt.' ---> 'Так, с 2006 года Google предлагает статистическую систему перевода.[5] Также были разработаны подходы, основанные на правилах.'\n",
            "'Eines der bekanntesten Forschungsprojekte dieser Art ist die freie Software Apertium, die von der spanischen Regierung und der Regierung von Katalonien finanziert und an der Universität Alicante weiterentwickelt wird.' ---> 'Одним из самых известных исследовательских проектов такого рода является свободный программный продукт Apertium, финансируемый испанским правительством и правительством Каталонии и разрабатываемый в Университете Аликанте.'\n",
            "'Der Stand der MÜ im Jahr 2010 wurde von vielen Menschen als unbefriedigend bewertet.' ---> 'По состоянию МУ в 2010 году многие считали неудовлетворительным.'\n",
            "'Grundsätzlich versteht die Wissenschaft menschliche Sprache aber noch unzureichend.' ---> 'Но, по сути, наука еще недостаточно понимает человеческий язык.'\n",
            "'Die meisten Sprachwissenschaftler gingen gar davon aus, dass maschineller Übersetzung ohne über das reine Sprachverständnis weit hinausgehende Kompetenzen automatischer Systeme grundsätzliche Grenzen gesetzt sind, da viele Übersetzungen zudem große Mengen an konzeptuellem Wissen, Metawissen sowie Kenntnisse über die Konstitution menschlicher Umwelt allgemein und über die Konventionen sozialer Interaktion erfordern.' ---> 'Большинство лингвистов полагали, что машинный перевод, не имея знаний, выходящих за рамки простого понимания языка, имеет принципиальные ограничения, поскольку многие переводы также требуют больших объемов концептуальных знаний, метазнаний, а также знаний о конституции человеческой среды в целом и о конвенциях социального взаимодействия.'\n",
            "'Seit dem Jahr 2016 werden für Übersetzungsprogramme zunehmend künstliche neuronale Netze, d. h. künstliche Intelligenzen eingesetzt, wodurch der Fortschritt rasant zunahm.' ---> 'С 2016 года в переводных программах все больше используются искусственные нейронные сети, то есть искусственный интеллект, что приводит к быстрому росту прогресса.'\n",
            "'Beispiele sind DeepL, Google Übersetzer, Yandex.Translate sowie der Bing Translator, die fortan deutlich bessere Ergebnisse erzielten.[6]' ---> 'Примерами являются DeepL, Google Translator, Yandex.Translate и Bing Translator, которые получили значительно лучшие результаты.[6]'\n",
            "'Im März 2018 teilte Microsoft mit, durch eine KI Chinesisch-Englisch-Übersetzungen mit der Qualität eines professionellen menschlichen Übersetzers zu erreichen.' ---> 'В марте 2018 года Microsoft объявила о том, что с помощью искусственного интеллекта достигнет китайско-английских переводов с качеством профессионального человеческого переводчика.'\n",
            "'Das sei ein Durchbruch bei der maschinellen Übersetzung, den Microsoft nicht so früh erwartet habe.[7][8]' ---> 'Это был прорыв в машинном переводе, который Microsoft не ожидала так рано.[7][8]'\n",
            "'Der Bedarf an MÜ-Anwendungen steigt weiter:' ---> 'Потребность в МО применений продолжает расти:'\n",
            "'Viele Texte sind heute digital verfügbar (also leicht für den Computer zu verarbeiten).' ---> 'Сегодня многие тексты доступны в цифровом виде (то есть легко обрабатываться на компьютере).'\n",
            "'Die Globalisierung erfordert die Übertragung von immer mehr Texten in immer mehr Sprachen (der Markt für Übersetzung verdoppelt sich alle vier Jahre), während die Popularität des Berufs des Übersetzers/Dolmetschers stagniert.' ---> 'Глобализация требует перевода все большего количества текстов на все большее количество языков (рынок перевода удваивается каждые четыре года), в то время как популярность профессии переводчика / переводчика стагнирует.'\n",
            "'Gerade von nur wenigen Westeuropäern/Amerikanern gesprochene beziehungsweise für diese schwierig zu erlernende Sprachen aus Regionen, deren Bewohner ihrerseits kaum westliche Sprachen sprechen, werden immer wichtiger:' ---> 'Языки, которые говорят лишь немногие западноевропейцы/американцы, или языки, которые трудно выучить, из регионов, жители которых, в свою очередь, редко говорят западные языки, становятся все более важными:'\n",
            "'kommerziell wichtig: die ostasiatischen Sprachen Chinesisch, Koreanisch und Japanisch; sowie Thai.' ---> 'Коммерчески важные: китайский, корейский и японский, а также тайский.'\n",
            "'militärisch wichtig: Sprachen der internationalen Konfliktregionen, vor allem mit Beteiligung des US-Militärs.' ---> 'Военно важно: языки международных конфликтных регионов, особенно с участием американских военных.'\n",
            "'2003 haben gleich mehrere US-Software-Unternehmen Übersetzungsprogramme für Arabisch und Paschtu (eine der Sprachen in Afghanistan und Grenzregionen Pakistans) herausgebracht.' ---> 'В 2003 году несколько американских программных компаний выпустили программы перевода на арабский и пашту (один из языков Афганистана и пограничных регионов Пакистана).'\n",
            "'Ebenfalls 2003 hat die DARPA einen Blind-Wettbewerb für eine unbekannte Ausgangssprache durchgeführt.' ---> 'Также в 2003 году DARPA провела конкурс на изучение неизвестного языка.'\n",
            "'2011 wurde das BOLT-Programm gestartet, das zum Ziel hat, die Erforschung der Übersetzung chinesischer und arabischer Texte ins Englische zu fördern.[9][10]' ---> 'В 2011 году была запущена программа BOLT, которая направлена на содействие исследованию перевода китайских и арабских текстов на английский язык.[9][10]'\n"
          ]
        }
      ],
      "source": [
        "for s, t in zip(norm_texts, tgt_texts):\n",
        "  if len(s):\n",
        "    print(f\"{s!r} ---> {t!r}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}